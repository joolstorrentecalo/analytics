{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb7eadbd-7adf-4c53-ac07-3c2dec095ff1",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# this is a parameter that will get overwritten when run by papermill on a schedules\n",
    "is_local_development = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c91380-795a-4b87-aa26-a02aae5be6c4",
   "metadata": {},
   "source": [
    "# Jupyter JSON upload notebook\n",
    "\n",
    "The goal is to have a template on how to upload data to Snowflake using pandas dataframe upload and a JSON approach.\n",
    "\n",
    "The model leverages or is inspired by the following libraries:\n",
    "\n",
    "- [Gitlab Orchestation Utils](https://gitlab.com/gitlab-data/gitlab-data-utils/-/blob/master/gitlabdata/orchestration_utils.py#L282)\n",
    "- [Data Science Scoring repo](https://gitlab.com/gitlab-data/data-science-projects/propensity-to-contract-and-churn/-/blob/main/prod/scoring_code.ipynb)\n",
    "\n",
    "## Status:\n",
    "\n",
    "20230215 NF: \n",
    "\n",
    "\n",
    "The JSON upload process works but only for smaller files (no more than 16MB). That seriously hampers its usefulness. \n",
    "\n",
    "The data frame upload process took around 19 minutes to execute the upload for a file of 200k rows. It is slow but it works.\n",
    "\n",
    "A parameter and a code to handle production vs local run was added to the template. Also the gsheet write function works. Just wondering if we could pass the value as a parameter instead as of a OS variable. \n",
    "\n",
    "The JSON file had this error regarding size: \n",
    "\n",
    "```\n",
    "ProgrammingError: (snowflake.connector.errors.ProgrammingError) 100069 (22P02): 01aa607c-0405-b753-0000-289d4df5c93a: Error parsing JSON: document is too large, max size 16777216 bytes\n",
    "  File 'stages/b712926c-eb9b-4af5-b02c-a2ae80ce832a/upa_summary.json.gz', line 1, character 16777216\n",
    "  Row 0, column $1\n",
    "  If you would like to continue loading when an error is encountered, use other values such as 'SKIP_FILE' or 'CONTINUE' for the ON_ERROR option. For more information on loading options, please run 'info loading_data' in a SQL client.\n",
    "[SQL: copy into raw.sales_analytics.upa_summary_json (jsontext)\n",
    "                         from @raw.sales_analytics.sales_analytics_load\n",
    "                         file_format=(type='json'),\n",
    "                         on_error='abort_statement';]\n",
    "(Background on this error at: https://sqlalche.me/e/14/f405)\n",
    "\n",
    "-----------------------------\n",
    "20230207 NF: The Dataframe upload process works, but the JSON process stills fails with an error \n",
    "\n",
    "```\n",
    "(snowflake.connector.errors.ProgrammingError) 000904 (42000): 01aa2b92-0405-a900-0000-289d4d4d634a: SQL compilation error: error line 1 at position 43\n",
    "invalid identifier 'JSONTEXT'\n",
    "[SQL: copy into raw.sales_analytics.upa_summary (jsontext)\n",
    "                         from @raw.sales_analytics.sales_analytics_load\n",
    "                         file_format=(type='json'),\n",
    "                         on_error='skip_file';]\n",
    "```\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f4fedc-eda4-4891-a74f-975d06d25733",
   "metadata": {},
   "source": [
    "## Local variable set up:\n",
    "\n",
    "A local variable in the file .dbt/profiles.yml needs to be created\n",
    "\n",
    "```\n",
    "output:\n",
    "   sales_analytics_local:\n",
    "     type: snowflake\n",
    "     threads: 16\n",
    "     account: gitlab\n",
    "     user: janesmith@gitlab.com # <-- This will be your GitLab email\n",
    "     role: sales_analytics # <-- Talk to your manager, usually, it is JSMITH for Jane Smith\n",
    "     database: RAW\n",
    "     warehouse: DEV_XS # <-- [ANALYST_XS, ENGINEER_XS], depends on your role\n",
    "     schema: SALES_ANALYTICS\n",
    "     authenticator: externalbrowser #\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e54f0d7c-69dc-4896-819e-263b14ff9b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pygsheets in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (2.0.5)\n",
      "Requirement already satisfied: google-auth-oauthlib in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from pygsheets) (0.7.1)\n",
      "Requirement already satisfied: google-api-python-client>=1.5.5 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from pygsheets) (1.6.0)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-api-python-client>=1.5.5->pygsheets) (0.15.0)\n",
      "Requirement already satisfied: six<2dev,>=1.6.1 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-api-python-client>=1.5.5->pygsheets) (1.16.0)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-api-python-client>=1.5.5->pygsheets) (3.0.1)\n",
      "Requirement already satisfied: oauth2client<5.0.0dev,>=1.5.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-api-python-client>=1.5.5->pygsheets) (4.1.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from oauth2client<5.0.0dev,>=1.5.0->google-api-python-client>=1.5.5->pygsheets) (0.2.8)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from oauth2client<5.0.0dev,>=1.5.0->google-api-python-client>=1.5.5->pygsheets) (4.7.2)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from oauth2client<5.0.0dev,>=1.5.0->google-api-python-client>=1.5.5->pygsheets) (0.4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-auth-oauthlib->pygsheets) (1.3.0)\n",
      "Requirement already satisfied: google-auth>=2.14.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-auth-oauthlib->pygsheets) (2.14.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-auth>=2.14.0->google-auth-oauthlib->pygsheets) (4.2.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->pygsheets) (3.1.1)\n",
      "Requirement already satisfied: requests>=2.0.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->pygsheets) (2.26.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib->pygsheets) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib->pygsheets) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib->pygsheets) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib->pygsheets) (2.0.7)\n",
      "Requirement already satisfied: pyarrow<5.1.0,>=5.0.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (5.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from pyarrow<5.1.0,>=5.0.0) (1.20.3)\n",
      "Requirement already satisfied: google.cloud in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (0.34.0)\n",
      "Requirement already satisfied: pandas_gbq in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (0.19.1)\n",
      "Requirement already satisfied: setuptools in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from pandas_gbq) (57.4.0)\n",
      "Requirement already satisfied: pydata-google-auth>=1.5.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from pandas_gbq) (1.5.0)\n",
      "Requirement already satisfied: pyarrow>=3.0.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from pandas_gbq) (5.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from pandas_gbq) (1.3.4)\n",
      "Requirement already satisfied: db-dtypes<2.0.0,>=1.0.4 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from pandas_gbq) (1.0.4)\n",
      "Requirement already satisfied: google-cloud-bigquery!=2.4.*,<4.0.0dev,>=3.3.5 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from pandas_gbq) (3.4.0)\n",
      "Requirement already satisfied: google-cloud-bigquery-storage<3.0.0dev,>=2.16.2 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from pandas_gbq) (2.16.2)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from pandas_gbq) (1.20.3)\n",
      "Requirement already satisfied: google-auth>=2.13.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from pandas_gbq) (2.14.1)\n",
      "Requirement already satisfied: google-api-core<3.0.0dev,>=2.10.2 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from pandas_gbq) (2.10.2)\n",
      "Requirement already satisfied: google-auth-oauthlib>=0.7.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from pandas_gbq) (0.7.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from db-dtypes<2.0.0,>=1.0.4->pandas_gbq) (21.2)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-api-core<3.0.0dev,>=2.10.2->pandas_gbq) (4.21.9)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-api-core<3.0.0dev,>=2.10.2->pandas_gbq) (1.57.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-api-core<3.0.0dev,>=2.10.2->pandas_gbq) (2.26.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-auth>=2.13.0->pandas_gbq) (1.16.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-auth>=2.13.0->pandas_gbq) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-auth>=2.13.0->pandas_gbq) (4.7.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-auth>=2.13.0->pandas_gbq) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-auth-oauthlib>=0.7.0->pandas_gbq) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-cloud-bigquery!=2.4.*,<4.0.0dev,>=3.3.5->pandas_gbq) (2.8.2)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.47.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-cloud-bigquery!=2.4.*,<4.0.0dev,>=3.3.5->pandas_gbq) (1.50.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-cloud-bigquery!=2.4.*,<4.0.0dev,>=3.3.5->pandas_gbq) (1.22.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-cloud-bigquery!=2.4.*,<4.0.0dev,>=3.3.5->pandas_gbq) (2.1.0)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-cloud-bigquery!=2.4.*,<4.0.0dev,>=3.3.5->pandas_gbq) (2.1.0)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-api-core<3.0.0dev,>=2.10.2->pandas_gbq) (1.41.1)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery!=2.4.*,<4.0.0dev,>=3.3.5->pandas_gbq) (1.3.0)\n",
      "Requirement already satisfied: pyparsing<3,>=2.0.2 in /Users/nfiguera/anaconda3/lib/python3.8/site-packages (from packaging>=17.0->db-dtypes<2.0.0,>=1.0.4->pandas_gbq) (2.4.7)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from pandas>=1.1.4->pandas_gbq) (2021.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.13.0->pandas_gbq) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3.0.0dev,>=2.10.2->pandas_gbq) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3.0.0dev,>=2.10.2->pandas_gbq) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3.0.0dev,>=2.10.2->pandas_gbq) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3.0.0dev,>=2.10.2->pandas_gbq) (1.26.7)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.7.0->pandas_gbq) (3.1.1)\n",
      "Requirement already satisfied: pyprojroot in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "# install required packages\n",
    "!{sys.executable} -m pip install  pygsheets\n",
    "!{sys.executable} -m pip install \"pyarrow<5.1.0,>=5.0.0;\"\n",
    "!{sys.executable} -m pip install --upgrade google.cloud\n",
    "!{sys.executable} -m pip install --upgrade pandas_gbq\n",
    "!{sys.executable} -m pip install pyprojroot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "767ea420-4035-4424-be29-cf7cdb9722e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gitlabdata in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (0.3.22)\n",
      "Requirement already satisfied: pygsheets==2.0.5 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from gitlabdata) (2.0.5)\n",
      "Requirement already satisfied: snowflake-sqlalchemy>=1.1.10 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from gitlabdata) (1.3.2)\n",
      "Requirement already satisfied: pyyaml==5.4.1 in /Users/nfiguera/anaconda3/lib/python3.8/site-packages (from gitlabdata) (5.4.1)\n",
      "Requirement already satisfied: pandas>=0.25.3 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from gitlabdata) (1.3.4)\n",
      "Requirement already satisfied: google-auth-oauthlib in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from pygsheets==2.0.5->gitlabdata) (0.7.1)\n",
      "Requirement already satisfied: google-api-python-client>=1.5.5 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from pygsheets==2.0.5->gitlabdata) (1.6.0)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-api-python-client>=1.5.5->pygsheets==2.0.5->gitlabdata) (0.15.0)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-api-python-client>=1.5.5->pygsheets==2.0.5->gitlabdata) (3.0.1)\n",
      "Requirement already satisfied: oauth2client<5.0.0dev,>=1.5.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-api-python-client>=1.5.5->pygsheets==2.0.5->gitlabdata) (4.1.3)\n",
      "Requirement already satisfied: six<2dev,>=1.6.1 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-api-python-client>=1.5.5->pygsheets==2.0.5->gitlabdata) (1.16.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from oauth2client<5.0.0dev,>=1.5.0->google-api-python-client>=1.5.5->pygsheets==2.0.5->gitlabdata) (0.4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from oauth2client<5.0.0dev,>=1.5.0->google-api-python-client>=1.5.5->pygsheets==2.0.5->gitlabdata) (0.2.8)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from oauth2client<5.0.0dev,>=1.5.0->google-api-python-client>=1.5.5->pygsheets==2.0.5->gitlabdata) (4.7.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from pandas>=0.25.3->gitlabdata) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from pandas>=0.25.3->gitlabdata) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from pandas>=0.25.3->gitlabdata) (1.20.3)\n",
      "Requirement already satisfied: snowflake-connector-python<3.0.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from snowflake-sqlalchemy>=1.1.10->gitlabdata) (2.7.0)\n",
      "Requirement already satisfied: sqlalchemy<2.0.0,>=1.4.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from snowflake-sqlalchemy>=1.1.10->gitlabdata) (1.4.26)\n",
      "Requirement already satisfied: pycryptodomex!=3.5.0,<4.0.0,>=3.2 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from snowflake-connector-python<3.0.0->snowflake-sqlalchemy>=1.1.10->gitlabdata) (3.11.0)\n",
      "Requirement already satisfied: cffi<2.0.0,>=1.9 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from snowflake-connector-python<3.0.0->snowflake-sqlalchemy>=1.1.10->gitlabdata) (1.15.0)\n",
      "Requirement already satisfied: asn1crypto<2.0.0,>0.24.0 in /Users/nfiguera/anaconda3/lib/python3.8/site-packages (from snowflake-connector-python<3.0.0->snowflake-sqlalchemy>=1.1.10->gitlabdata) (1.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from snowflake-connector-python<3.0.0->snowflake-sqlalchemy>=1.1.10->gitlabdata) (3.3)\n",
      "Requirement already satisfied: setuptools>34.0.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from snowflake-connector-python<3.0.0->snowflake-sqlalchemy>=1.1.10->gitlabdata) (57.4.0)\n",
      "Requirement already satisfied: oscrypto<2.0.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from snowflake-connector-python<3.0.0->snowflake-sqlalchemy>=1.1.10->gitlabdata) (1.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from snowflake-connector-python<3.0.0->snowflake-sqlalchemy>=1.1.10->gitlabdata) (2021.10.8)\n",
      "Requirement already satisfied: requests<3.0.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from snowflake-connector-python<3.0.0->snowflake-sqlalchemy>=1.1.10->gitlabdata) (2.26.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from snowflake-connector-python<3.0.0->snowflake-sqlalchemy>=1.1.10->gitlabdata) (2.0.7)\n",
      "Requirement already satisfied: pyOpenSSL<21.0.0,>=16.2.0 in /Users/nfiguera/anaconda3/lib/python3.8/site-packages (from snowflake-connector-python<3.0.0->snowflake-sqlalchemy>=1.1.10->gitlabdata) (20.0.1)\n",
      "Requirement already satisfied: cryptography<4.0.0,>=3.1.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from snowflake-connector-python<3.0.0->snowflake-sqlalchemy>=1.1.10->gitlabdata) (3.4.8)\n",
      "Requirement already satisfied: pyjwt<3.0.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from snowflake-connector-python<3.0.0->snowflake-sqlalchemy>=1.1.10->gitlabdata) (2.3.0)\n",
      "Requirement already satisfied: pycparser in /Users/nfiguera/anaconda3/lib/python3.8/site-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python<3.0.0->snowflake-sqlalchemy>=1.1.10->gitlabdata) (2.20)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from requests<3.0.0->snowflake-connector-python<3.0.0->snowflake-sqlalchemy>=1.1.10->gitlabdata) (1.26.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from sqlalchemy<2.0.0,>=1.4.0->snowflake-sqlalchemy>=1.1.10->gitlabdata) (1.1.2)\n",
      "Requirement already satisfied: google-auth>=2.14.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-auth-oauthlib->pygsheets==2.0.5->gitlabdata) (2.14.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-auth-oauthlib->pygsheets==2.0.5->gitlabdata) (1.3.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from google-auth>=2.14.0->google-auth-oauthlib->pygsheets==2.0.5->gitlabdata) (4.2.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->pygsheets==2.0.5->gitlabdata) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install gitlabdata --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edea41d9-b0a0-415d-998a-9e7c0f3b8312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygsheets\n",
    "import configparser\n",
    "import sys\n",
    "import snowflake.connector\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np                   # v 1.19.2\n",
    "import matplotlib.pyplot as plt      # v 3.3.2\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.ticker as ticker\n",
    "# calculate the net_arr bucket of open deals\n",
    "import seaborn as sns\n",
    "from math import floor \n",
    "from datetime import date\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# https://pypi.org/project/pyprojroot/\n",
    "from pyprojroot import here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ca065e8-5fc5-409a-a428-5eb2d9e3ad72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gitlabdata.orchestration_utils import (\n",
    "    data_science_engine_factory,\n",
    "    query_dataframe,\n",
    "    snowflake_engine_factory,\n",
    "    snowflake_stage_load_copy_remove,\n",
    "    get_env_from_profile,\n",
    "    dataframe_uploader,\n",
    "    write_to_gsheets,\n",
    "    query_executor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15ccc542-bd5c-4e93-b7a2-418d2152352b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nfiguera/repos/sales-strategy-and-analytics-business-intelligence/jupyter_dev/202302_Jupyter_to_Snowflake_demo\n"
     ]
    }
   ],
   "source": [
    "import os as os\n",
    "os.getcwd()\n",
    "\n",
    "# NF: Just to deal with my working directory changing\n",
    "# Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "#os.chdir(\"/Users/nfiguera/repos/sales-strategy-and-analytics-business-intelligence/jupyter_dev/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a898e93-3838-4401-842e-320b4336557a",
   "metadata": {},
   "source": [
    "## Create Snowflake engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "859777a1-99e7-42a1-a2eb-a895ba919c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Engine(snowflake://nfiguera%40gitlab.com:***@gitlab/RAW/?authenticator=externalbrowser&role=NFIGUERA&warehouse=DEV_XS)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# engine factory can be created using a local role from output\n",
    "# depending on this notebook being run locally or remotely, the \n",
    "# engine is creation process is different\n",
    "\n",
    "if is_local_development:\n",
    "    snowflake_engine = data_science_engine_factory(profile_target=\"sales_analytics_local\")\n",
    "else:\n",
    "    snowflake_engine = snowflake_engine_factory(env, \"sales_analytics\")\n",
    "\n",
    "snowflake_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b356fa-3547-4608-a852-52ff741c6e91",
   "metadata": {},
   "source": [
    "## Excute Snowflake query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed438cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def executeScriptFromFile(filename, engine):\n",
    "    # Open and read the file as a single buffer\n",
    "    fd = open(filename, 'r')\n",
    "    sqlFile = fd.read()\n",
    "    fd.close()\n",
    "\n",
    "    print(filename)\n",
    "    print(len(sqlFile))\n",
    "\n",
    "    results = -1\n",
    "\n",
    "    try:\n",
    "        results = query_dataframe(engine, sqlFile)\n",
    "    except:\n",
    "        print(\"Command did not run\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d611210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbt_bob_upa.sql\n",
      "116\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "170589075.80999997"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upa_summary = executeScriptFromFile('dbt_bob_upa.sql', snowflake_engine)\n",
    "\n",
    "# TEST Total FY Net ARR\n",
    "index = (upa_summary['report_fiscal_year'] == 2023)\n",
    "upa_summary[index].fy_booked_net_arr.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54ec218f-85cf-4ec3-92e2-012799c81475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the credentials of the google service account\n",
    "import json, os\n",
    "\n",
    "if is_local_development:\n",
    "    credentials_path = here('credentials/gsheet_service_file.json')\n",
    "\n",
    "    with open(credentials_path) as f:\n",
    "       service_account_credentials = f.read().replace('\\n', '')\n",
    "\n",
    "    # set the credential as a enviroment variable\n",
    "    os.environ[\"GSHEETS_SERVICE_ACCOUNT_CREDENTIALS\"] = service_account_credentials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f723d4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Writing data to sheet rigerta_testing_2...\n",
      "INFO:googleapiclient.discovery:URL being requested: POST https://sheets.googleapis.com/v4/spreadsheets/1eRo30S0G4-QkGBdpz7jBmRSRsMHkfysfi_xv2ab_28Q:batchUpdate?fields=replies%2FaddSheet&alt=json\n",
      "INFO:googleapiclient.discovery:URL being requested: POST https://sheets.googleapis.com/v4/spreadsheets/1eRo30S0G4-QkGBdpz7jBmRSRsMHkfysfi_xv2ab_28Q:batchUpdate?fields=%2A&alt=json\n",
      "INFO:googleapiclient.discovery:URL being requested: PUT https://sheets.googleapis.com/v4/spreadsheets/1eRo30S0G4-QkGBdpz7jBmRSRsMHkfysfi_xv2ab_28Q/values/rigerta_testing_2%21A1%3ADE102?valueInputOption=USER_ENTERED&alt=json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nfiguera/.local/share/virtualenvs/data-science-mn1T8veA/lib/python3.8/site-packages/pygsheets/worksheet.py:1366: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype('unicode').replace('<NA>', nan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:googleapiclient.discovery:URL being requested: POST https://sheets.googleapis.com/v4/spreadsheets/1eRo30S0G4-QkGBdpz7jBmRSRsMHkfysfi_xv2ab_28Q:batchUpdate?fields=%2A&alt=json\n"
     ]
    }
   ],
   "source": [
    "# Write to GSheets\n",
    "sheet_id = '1eRo30S0G4-QkGBdpz7jBmRSRsMHkfysfi_xv2ab_28Q'\n",
    "sheet_name = 'new_nf_testing'\n",
    "write_to_gsheets(sheet_id, sheet_name, upa_summary.head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682d5ac2-0eb2-4f04-a37a-57104933f1f9",
   "metadata": {},
   "source": [
    "## Test to_sql from pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "950bdf44-f11e-4056-96ea-1100d7ef7ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239935\n",
      "INFO:snowflake.connector.connection:Snowflake Connector for Python Version: 2.7.0, Python Version: 3.8.8, Platform: macOS-10.16-x86_64-i386-64bit\n",
      "INFO:snowflake.connector.connection:This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.\n",
      "INFO:snowflake.connector.cursor:query: [ROLLBACK]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [DESC TABLE /* sqlalchemy:_has_object */ \"SALES_ANALYTICS\".upa_summary]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [ROLLBACK]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [ROLLBACK]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [DESC TABLE /* sqlalchemy:_has_object */ \"SALES_ANALYTICS\".upa_summary]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [ROLLBACK]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [ROLLBACK]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [SHOW /* sqlalchemy:get_table_names */ TABLES IN \"SALES_ANALYTICS\"]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [SHOW /* sqlalchemy:_get_schema_primary_keys */PRIMARY KEYS IN SCHEMA raw.\"SALES_...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [SELECT /* sqlalchemy:_get_schema_columns */ ic.table_name, ic.column_name, ic.da...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [SHOW /* sqlalchemy:_get_schema_foreign_keys */ IMPORTED KEYS IN SCHEMA raw.\"SALE...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [SHOW /* sqlalchemy:_get_table_comment */ TABLES LIKE 'upa_summary' IN SCHEMA sal...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [ROLLBACK]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [DROP TABLE \"SALES_ANALYTICS\".upa_summary]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [COMMIT]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [ROLLBACK]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [CREATE TABLE \"SALES_ANALYTICS\".upa_summary ( report_fiscal_year BIGINT, upa_type...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [COMMIT]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [ROLLBACK]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [INSERT INTO \"SALES_ANALYTICS\".upa_summary (report_fiscal_year, upa_type, upa_id,...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [INSERT INTO \"SALES_ANALYTICS\".upa_summary (report_fiscal_year, upa_type, upa_id,...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [INSERT INTO \"SALES_ANALYTICS\".upa_summary (report_fiscal_year, upa_type, upa_id,...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [INSERT INTO \"SALES_ANALYTICS\".upa_summary (report_fiscal_year, upa_type, upa_id,...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [INSERT INTO \"SALES_ANALYTICS\".upa_summary (report_fiscal_year, upa_type, upa_id,...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [INSERT INTO \"SALES_ANALYTICS\".upa_summary (report_fiscal_year, upa_type, upa_id,...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [INSERT INTO \"SALES_ANALYTICS\".upa_summary (report_fiscal_year, upa_type, upa_id,...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [INSERT INTO \"SALES_ANALYTICS\".upa_summary (report_fiscal_year, upa_type, upa_id,...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [INSERT INTO \"SALES_ANALYTICS\".upa_summary (report_fiscal_year, upa_type, upa_id,...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [INSERT INTO \"SALES_ANALYTICS\".upa_summary (report_fiscal_year, upa_type, upa_id,...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [INSERT INTO \"SALES_ANALYTICS\".upa_summary (report_fiscal_year, upa_type, upa_id,...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [INSERT INTO \"SALES_ANALYTICS\".upa_summary (report_fiscal_year, upa_type, upa_id,...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [INSERT INTO \"SALES_ANALYTICS\".upa_summary (report_fiscal_year, upa_type, upa_id,...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [INSERT INTO \"SALES_ANALYTICS\".upa_summary (report_fiscal_year, upa_type, upa_id,...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [INSERT INTO \"SALES_ANALYTICS\".upa_summary (report_fiscal_year, upa_type, upa_id,...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [INSERT INTO \"SALES_ANALYTICS\".upa_summary (report_fiscal_year, upa_type, upa_id,...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [INSERT INTO \"SALES_ANALYTICS\".upa_summary (report_fiscal_year, upa_type, upa_id,...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [INSERT INTO \"SALES_ANALYTICS\".upa_summary (report_fiscal_year, upa_type, upa_id,...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [INSERT INTO \"SALES_ANALYTICS\".upa_summary (report_fiscal_year, upa_type, upa_id,...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [INSERT INTO \"SALES_ANALYTICS\".upa_summary (report_fiscal_year, upa_type, upa_id,...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [INSERT INTO \"SALES_ANALYTICS\".upa_summary (report_fiscal_year, upa_type, upa_id,...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [INSERT INTO \"SALES_ANALYTICS\".upa_summary (report_fiscal_year, upa_type, upa_id,...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [INSERT INTO \"SALES_ANALYTICS\".upa_summary (report_fiscal_year, upa_type, upa_id,...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [INSERT INTO \"SALES_ANALYTICS\".upa_summary (report_fiscal_year, upa_type, upa_id,...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [COMMIT]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [ROLLBACK]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "CPU times: user 2min 7s, sys: 3.84 s, total: 2min 11s\n",
      "Wall time: 28min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(len(upa_summary))\n",
    "\n",
    "# this works\n",
    "dataframe_uploader(\n",
    "    dataframe = upa_summary,\n",
    "    engine = snowflake_engine,\n",
    "    table_name = 'upa_summary',\n",
    "    schema = \"SALES_ANALYTICS\",\n",
    "    if_exists = \"replace\",\n",
    "    add_uploaded_at = False\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590c189e-8122-4363-b341-e56a88d05b72",
   "metadata": {},
   "source": [
    "## The JSON Upload process\n",
    "\n",
    "JSON process expects a table with two columns:\n",
    "- JSONTEXT with the JSON file as content\n",
    "- UPDATED AT\n",
    "\n",
    "The table is then processed by DBT models and exposed in prod as a flat table.\n",
    "\n",
    "**JSON upload only work for smaller files!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d11d64ea-bbf1-4d74-8038-1ba74abb1df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:snowflake.connector.cursor:query: [CREATE OR REPLACE TABLE raw.sales_analytics.upa_summary_json (jsontext string, u...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [ROLLBACK]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.connection:closed\n",
      "INFO:snowflake.connector.connection:No async queries seem to be running, deleting session\n",
      "INFO:snowflake.connector.connection:Snowflake Connector for Python Version: 2.7.0, Python Version: 3.8.8, Platform: macOS-10.16-x86_64-i386-64bit\n",
      "INFO:snowflake.connector.connection:This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.\n",
      "INFO:root:Clearing json files from stage.\n",
      "INFO:snowflake.connector.cursor:query: [remove @raw.sales_analytics.sales_analytics_load pattern='.*.json.gz']\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:root:Query successfully run\n",
      "INFO:root:Writing to Snowflake.\n",
      "INFO:snowflake.connector.cursor:query: [put 'file:///Users/nfiguera/repos/sales-strategy-and-analytics-business-intellig...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:root:Query successfully run\n",
      "INFO:snowflake.connector.cursor:query: [ROLLBACK]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.connection:closed\n",
      "INFO:snowflake.connector.connection:No async queries seem to be running, deleting session\n",
      "INFO:snowflake.connector.connection:Snowflake Connector for Python Version: 2.7.0, Python Version: 3.8.8, Platform: macOS-10.16-x86_64-i386-64bit\n",
      "INFO:snowflake.connector.connection:This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.\n",
      "INFO:root:Copying to Table raw.sales_analytics.upa_summary_json.\n",
      "INFO:snowflake.connector.cursor:query: [copy into raw.sales_analytics.upa_summary_json (jsontext) from @raw.sales_analyt...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [COMMIT]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:root:Query successfully run\n",
      "INFO:root:Removing /Users/nfiguera/repos/sales-strategy-and-analytics-business-intelligence/data/upa_summary.json from stage.\n",
      "INFO:snowflake.connector.cursor:query: [remove @raw.sales_analytics.sales_analytics_load pattern='.*.json.gz']\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:root:Query successfully run\n",
      "INFO:snowflake.connector.cursor:query: [ROLLBACK]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.connection:closed\n",
      "INFO:snowflake.connector.connection:No async queries seem to be running, deleting session\n",
      "CPU times: user 943 ms, sys: 72.7 ms, total: 1.02 s\n",
      "Wall time: 40.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# OUTPUT SCORES TO JSON\n",
    "output_filename = here(\"data/upa_summary.json\")\n",
    "\n",
    "# test with only 10 rows\n",
    "output_scores = upa_summary.head(1000)\n",
    "output_scores.to_json(output_filename, orient=\"records\", date_format=\"iso\")\n",
    "\n",
    "# this table is later processed using dbt models\n",
    "json_tablename = 'raw.sales_analytics.upa_summary_json'\n",
    "\n",
    "# creation of target table\n",
    "create_json_table_query = 'CREATE OR REPLACE TABLE {} (jsontext string, updated_at date)'.format(json_tablename)\n",
    "\n",
    "# create or replace existing table with the JSON expected format\n",
    "query_executor(snowflake_engine, create_json_table_query)\n",
    "\n",
    "snowflake_stage_load_copy_remove(\n",
    "    output_filename,\n",
    "    f\"raw.sales_analytics.sales_analytics_load\",\n",
    "    json_tablename,\n",
    "    snowflake_engine,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e1b8c5-fac0-4039-92f6-6c3aee7da39a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "ea4f0e1d1faa5bb96f695d7e31ce7a9817f73b9836258768e692d46b900aef52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
